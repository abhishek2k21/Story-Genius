# ðŸ”´ Error Analysis: "Generation Failed" Issue

## Summary
**Current Status**: âŒ FAILING  
**Root Cause**: Missing Google Cloud credentials for Vertex AI LLM  
**Impact**: Video generation cannot proceed (Generation Failed error)  
**Severity**: CRITICAL

---

## Error Details

### What Happens When You Click "Generate Video"

1. **Frontend Action**: User clicks "Generate Video" button
   - Sends POST to `/v1/shorts/generate`
   - Request body includes: platform, audience, topic, duration

2. **API Response**: Returns job_id immediately (HTTP 200)
   - This works fine âœ…
   - Job ID is assigned
   - Status shown as "queued"

3. **Background Processing**: Job fails silently âŒ
   - Location: Background task in `run_job_background()`
   - The orchestrator tries to initialize LLM
   - Vertex AI initialization fails due to missing credentials
   - Job status updated to "failed"
   - Error: "Unknown error occurred"

4. **Frontend Display**: Shows error message
   - No detailed error info returned to UI
   - Just shows "Generation Failed"
   - User has no visibility into root cause

---

## Root Cause Analysis

### Issue: Missing Google Cloud Credentials

**File**: `StoryGenius/story_genius/llm/vertex_wrapper.py`

```python
def _initialize(self):
    try:
        # This line fails without credentials
        vertexai.init(project=self.project_id, location=self.location)
        self.model = GenerativeModel(self.model_name)
```

**Why It Fails**:
- Vertex AI SDK requires authentication
- Expected env var: `GOOGLE_APPLICATION_CREDENTIALS`
- Current value: **NOT SET** (empty)
- Fall back to system authentication: **NOT CONFIGURED**

**Project ID**: `winged-precept-458206-j1` (hardcoded in wrapper)

---

## Call Stack

```
POST /v1/shorts/generate
  â†“
routes.py::generate_shorts()
  â†“
background_tasks.add_task(run_job_background)
  â†“
run_job_background(job_id)
  â†“
orchestrator.start_job(job_id)
  â†“
StoryAdapter(job)
  â†“
story_adapter.generate_story(use_hook_engine=True)
  â†“
llm = self._get_llm()
  â†“
VertexLLM()._initialize()  â† FAILS HERE âŒ
  â†“
vertexai.init(project=..., location=...)  â† GOOGLE AUTH REQUIRED
  â†“
Exception: Authentication failed (no credentials found)
```

---

## Error Message Flow

1. **Backend**: `Exception: Failed to initialize LLM: [Google auth error]`
2. **Database**: Error stored in `DBJob.error_message`
3. **API**: `GET /v1/jobs/{job_id}` returns error_message
4. **Frontend**: Displays generic "Generation Failed - Unknown error occurred"

---

## Database Record

When you check the job status after failure:

```json
{
  "job_id": "xxxxx-xxxxx-xxxxx",
  "status": "failed",
  "error_message": "(exact error from Google Auth library)",
  "created_at": "2026-01-29T...",
  "updated_at": "2026-01-29T..."
}
```

The error_message contains the actual error but frontend doesn't display it properly.

---

## Solution: How to Fix

### Option 1: Use Google Cloud Service Account (RECOMMENDED)

**Steps**:

1. **Get Google Cloud Credentials**
   ```bash
   # If you have Google Cloud project access:
   gcloud auth application-default login
   
   # Or create service account:
   # 1. Go to: https://console.cloud.google.com/
   # 2. Create service account with Vertex AI permissions
   # 3. Download JSON key file
   ```

2. **Set Environment Variable**
   ```powershell
   # Windows PowerShell
   $env:GOOGLE_APPLICATION_CREDENTIALS = "C:\path\to\service-account-key.json"
   
   # Verify it's set:
   echo $env:GOOGLE_APPLICATION_CREDENTIALS
   ```

3. **Restart Backend**
   ```bash
   # Kill current uvicorn process
   taskkill /F /IM python.exe
   
   # Restart with new env var
   python -m uvicorn app.api.main:app --reload --host 0.0.0.0 --port 8000
   ```

4. **Test**
   - Go back to Create Video page
   - Click "Generate Video"
   - Should now process without "Generation Failed"

---

### Option 2: Mock LLM for Development

**If you don't have Google Cloud access yet**:

1. **Create a mock LLM service** (temporary, for testing):

```python
# File: app/story/mock_llm.py
class MockLLM:
    def __init__(self, project_id=None, location=None, model_name=None):
        self.project_id = project_id
        print(f"Mock LLM initialized (no real Google credentials needed)")

    def generate_content(self, prompt, system_instruction=None, temperature=0.7):
        # Return sample story structure for testing
        return MockResponse("""
        [
            {
                "scene_number": 1,
                "narration_text": "Ever wonder how this started?",
                "visual_prompt": "Professional cinematic opening shot"
            },
            {
                "scene_number": 2,
                "narration_text": "The journey began here.",
                "visual_prompt": "Historical setting with warm colors"
            }
        ]
        """)

class MockResponse:
    def __init__(self, text):
        self.text = text
```

2. **Update vertex_wrapper.py** to use mock:

```python
# In vertex_wrapper.py, modify imports:
try:
    from vertexai.generative_models import GenerativeModel, SafetySetting
    USE_REAL_VERTEX = True
except ImportError:
    USE_REAL_VERTEX = False
    from app.story.mock_llm import MockLLM as GenerativeModel

# In __init__:
if not USE_REAL_VERTEX:
    print("WARNING: Using Mock LLM (no real Google credentials)")
```

3. **Test with mock** while getting real credentials

---

## Files That Need Changes

### Primary Issue
- **`StoryGenius/story_genius/llm/vertex_wrapper.py`** (line 13-17)
  - Fails during `vertexai.init()`
  - Needs Google Cloud credentials

### Secondary Issues
- **`app/api/routes.py`** (line 50)
  - Error handling should return actual error message to frontend
  - Currently just returns generic 500

- **`frontend/src/lib/api-client.ts`** (line 110-120)
  - Should display actual error message from backend
  - Currently shows "Unknown error occurred"

---

## Detailed Error Message (If You Check Logs)

When running the generation, the actual error is something like:

```
Failed to initialize Vertex AI: 
  google.api_core.exceptions.NotFound: 404 Could not find gRPC config for service 'aiplatform.googleapis.com'
  
OR

google.auth.exceptions.DefaultCredentialsError: 
  Could not automatically determine credentials. 
  Please set GOOGLE_APPLICATION_CREDENTIALS 
  or explicitly create credentials and re-run the application.
```

---

## Verification Checklist

Before trying generation again:

- [ ] Check `$env:GOOGLE_APPLICATION_CREDENTIALS` is set
- [ ] Verify service account JSON file exists at that path
- [ ] Ensure service account has "Vertex AI User" role
- [ ] Check project ID in vertex_wrapper.py matches your Google project
- [ ] Backend has been restarted after setting env var
- [ ] Run `python -c "import vertexai; vertexai.init(project='winged-precept-458206-j1', location='us-central1'); print('âœ… Vertex AI initialized successfully')"` to test

---

## Testing the Fix

### Manual Test Script

```python
# File: test_vertex_init.py
import os
from StoryGenius.story_genius.llm.vertex_wrapper import VertexLLM

print("Credentials env var:", os.environ.get('GOOGLE_APPLICATION_CREDENTIALS'))

try:
    llm = VertexLLM()
    print("âœ… VertexLLM initialized successfully!")
    
    response = llm.generate_content("Say hello in JSON format")
    print("âœ… LLM responding:", response.text[:100])
except Exception as e:
    print("âŒ Error:", e)
    import traceback
    traceback.print_exc()
```

Run with:
```bash
python test_vertex_init.py
```

---

## What Happens After Fix

Once credentials are set:

1. **Generate Video button clicked** âœ…
2. **POST /v1/shorts/generate** receives request âœ…
3. **Job created** with status "queued" âœ…
4. **LLM initializes** successfully âœ…
5. **Story generated** using Vertex AI Gemini âœ…
6. **Media created** (audio, visuals) âœ…
7. **Job completes** with status "completed" âœ…
8. **Video returned** to frontend âœ…
9. **PlayVideo displayed** with results âœ…

---

## Current System Status

| Component | Status | Notes |
|-----------|--------|-------|
| Frontend | âœ… Working | Renders correctly, sends requests |
| Backend API | âœ… Working | Routes respond, database works |
| Database | âœ… Working | Jobs saved, status tracked |
| Authentication | âœ… Working | User login successful |
| Google Credentials | âŒ **NOT SET** | BLOCKS generation |
| Vertex AI LLM | âŒ Cannot init | Needs credentials |
| Story Generation | âŒ Fails | Blocked by LLM |
| Media Generation | â¸ï¸ Unreached | Blocked by story |
| Video Output | âŒ Not generated | End-to-end blocked |

---

## Quick Reference

**The Issue In One Sentence**:  
> Backend can't generate stories because it can't authenticate with Google Cloud Vertex AI LLM (missing credentials).

**The Fix In One Sentence**:  
> Set `GOOGLE_APPLICATION_CREDENTIALS` environment variable to your Google service account JSON file path.

**Time to Fix**: 5-10 minutes (if you have Google Cloud access)

---

## Need Help?

1. **Create Google Cloud Project**: https://console.cloud.google.com/
2. **Enable Vertex AI API**: Search "Vertex AI API" in console
3. **Create Service Account**: IAM & Admin â†’ Service Accounts
4. **Download JSON Key**: Actions menu â†’ Manage Keys â†’ Create Key
5. **Set Environment Variable**: See Option 1 above
6. **Restart Backend**: Kill python.exe and restart

---

## Summary Table

| Aspect | Detail |
|--------|--------|
| **Current Error** | Generation Failed - Unknown error occurred |
| **Root Cause** | Missing Google Cloud credentials (GOOGLE_APPLICATION_CREDENTIALS not set) |
| **Affected Component** | Story generation (Vertex AI LLM initialization) |
| **User Impact** | Cannot generate videos |
| **Fix Difficulty** | Easy (1 env var + restart) |
| **Fix Time** | 5-10 minutes |
| **Workaround** | Use mock LLM for testing |
| **Permanent Solution** | Get Google Cloud service account credentials |

